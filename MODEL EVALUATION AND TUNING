# ---------------------------------------------------------
# WEEK 8: Model Evaluation and Tuning
# Project: Student Performance Classification using RandomForest
# ---------------------------------------------------------

# Step 1: Import Required Libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# ---------------------------------------------------------
# Step 2: Create a Sample Dataset
# ---------------------------------------------------------
# Simulated dataset for student performance prediction
data = {
    'StudyHours': [1,2,3,4,5,6,7,8,9,10,2,4,6,8,10,3,5,7,9,10],
    'Attendance': [40,50,60,70,80,90,85,95,100,98,45,65,75,88,92,55,70,80,85,95],
    'Passed':     [0,0,0,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1]
}

# Convert to DataFrame
df = pd.DataFrame(data)
print("üìä Dataset Preview:")
print(df.head())

# ---------------------------------------------------------
# Step 3: Split the Data into Train/Test Sets
# ---------------------------------------------------------
X = df[['StudyHours', 'Attendance']]
y = df['Passed']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

print("\n‚úÖ Data Split Complete:")
print(f"Training Samples: {len(X_train)} | Testing Samples: {len(X_test)}")

# ---------------------------------------------------------
# Step 4: Train the Initial Model
# ---------------------------------------------------------
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Make Predictions
y_pred = model.predict(X_test)

# ---------------------------------------------------------
# Step 5: Evaluate the Model
# ---------------------------------------------------------
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("\nüìà Model Evaluation Metrics (Before Tuning):")
print(f"Accuracy:  {acc:.2f}")
print(f"Precision: {prec:.2f}")
print(f"Recall:    {rec:.2f}")
print(f"F1 Score:  {f1:.2f}")

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix (Before Tuning)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

# ---------------------------------------------------------
# Step 6: Cross-Validation
# ---------------------------------------------------------
cv_scores = cross_val_score(model, X, y, cv=5)
print("\nüîÅ Cross-Validation Scores (5-Fold):", cv_scores)
print("Average CV Accuracy:", np.mean(cv_scores).round(3))

# ---------------------------------------------------------
# Step 7: Hyperparameter Tuning using GridSearchCV
# ---------------------------------------------------------
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [2, 4, 6, None],
    'min_samples_split': [2, 3, 5]
}

grid_search = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_grid=param_grid,
    scoring='accuracy',
    cv=5,
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

print("\nüîç Best Parameters Found by GridSearchCV:")
print(grid_search.best_params_)
print("Best Cross-Validation Accuracy:", grid_search.best_score_.round(3))

# ---------------------------------------------------------
# Step 8: Evaluate the Tuned Model
# ---------------------------------------------------------
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test)

print("\nüìä Tuned Model Evaluation Metrics:")
print(classification_report(y_test, y_pred_best))

# Confusion Matrix for Tuned Model
cm_best = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(5,4))
sns.heatmap(cm_best, annot=True, fmt='d', cmap='Greens')
plt.title("Confusion Matrix (After Tuning)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

# ---------------------------------------------------------
# Step 9: Predict for New Student
# ---------------------------------------------------------
new_student = pd.DataFrame({'StudyHours': [7], 'Attendance': [90]})
prediction = best_model.predict(new_student)
print("\nüéì Predicted Result for New Student (1 = Pass, 0 = Fail):", prediction[0])
)
